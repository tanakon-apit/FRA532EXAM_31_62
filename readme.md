# FRA532 EXAM
## 1. Getting Started
## 1.1 Intallation package
To installation this project

```bash
git clone https://github.com/tanakon-apit/FRA532EXAM_31_62.git
cd FRA532EXAM_31_62
colcon build
source install/setup.bash
```
To automate workspace setup every time you open a new terminal, add the following line to your `~/.bashrc` or `~/.bash_profile` file:

```bash
echo "source ~/your_workspace/install/setup.bash" >> ~/.bashrc
source ~/.bashrc
```

## 1.2 Run Visualization Rviz.

### Setup Robot

To start setup robot by run

```bash
$ ros2 run micro_ros_agent micro_ros_agent udp4 --port 8888
```

Then Calibrate sensor

```bash
$ ros2 run calibration_gen cal_node.py
```

To start Run Visualization you can run launch file

```bash
$ ros2 launch robot_bridge robot_bridge.launch.py 
```

### To collect data of odom as csv to plot graph

```bash
$ ros2 run robot_bridge save_csv.py
```

### To controlling Robot

you can using keyboard to control robot
```bash
$ ros2 run teleop_twist_keyboard teleop_twist_keyboard 
```

or setting via-point to control robot
```bash
$ ros2 run robot_bridge via_points_generator.py
```

# 2. System overview
## 2.1 system_interface_diagram

![image](https://github.com/tanakon-apit/FRA532EXAM_31_62/assets/113016544/e4ee5e1c-c144-4a2c-a35d-411482d73e2a)

### Block Description

white box: hardware/ package / exacutable file

green box: subscript topic

blue box: publish topic

yellow box: tf

purple box: tunning parameter

### Back ground color Description

Orang back ground: Commanding part

Green back ground: Processing part

Blue back ground: Display part

## 2.2 rqt_graph 
```bash
rqt_graph
```
![Screenshot from 2024-02-22 19-28-23](https://github.com/tuchapong1234/Lab1-Local-Planner/assets/113016544/bd7dbe52-339f-4410-8ac3-f837e0a8310f)

## 5. Experiments

### 5.1 Find relationship between motor command & real output of Dynamixel

In testing to determine the correlation between Dynamixel commands and speed, we conducted experiments by comparing the code in the Motor.cpp file with the Dynamixel datasheet. Subsequently, validation was performed by instructing the robot to move forward at a speed of 0.1 m/s for 10 seconds and measuring the distance traveled. The expected distance should be close to 1 meter.

### 5.2 Find relationship between the values generated by the robot and the values of Wheel Odometry.

### Condition 1: Moving Forward 1 m then Backward 1 m

https://github.com/tanakon-apit/FRA532EXAM_31_62/assets/113016544/9325a1a2-178b-4a8d-a822-1c4dab0be017

Experiment Result
| x [actual] | y [actual] | x [estimated]| y [estimated]| x [error] | y [error] | x [square error] | y [square error] |
| :---: | :---:| :---: | :---: | :---: | :---:| :---: | :---: |
| -0.002 | -0.005 | -0.002 | -0.0325 | 0 | 0.0275 | 0.00075625 | 0.00075625 |
| -0.003 | -0.004 | -0.0041 | -0.0081 | 0.0011 | 0.0041 | 0.00000121 | 0.00001681 |
| -0.004 | -0.015 | -0.0045 | 0.0027 | 0.0005 | -0.0177 | 0.00000025 | 0.00031329 |
| 0.005 | -0.005 | 0.0115 | 0.0306 | -0.0065 | -0.0356 | 0.00004225 | 0.00126736 |
| -0.043 | -0.005 | -0.0454 | 0 | 0.0024 | -0.005 | 5.76E-06 | 0.000025 |
| -0.02 | -0.005 | -0.023 | -0.023 | 0.003 | 0.018 | 0.000009 | 0.000324 |
| 0.003 | -0.01 | -0.005 | -0.02 | 0.008 | 0.01 | 0.000064 | 0.0001 |
| 0.04 | -0.009 | 0.03 | -0.028 | 0.01 | 0.019 | 0.0001 | 0.000361 |
| 0.009 | -0.007 | 0.01 | -0.002 | -0.001 | -0.005 | 0.000001 | 0.000025 |
| -0.033 | -0.007 | -0.032 | -0.0029 | -0.001 | -0.0041 | 0.000001 | 0.00001681 |

| x [rmse] | y [rmse] |
| :---: | :---: |
| 0.004737827 | 0.017903966 |

### Condition 2: Moving as a Rectangel 1 m^2 

This part we don't save the experiment result because we don't have the measurement that can recieve a significant of real error of the orientation.

https://github.com/tanakon-apit/FRA532EXAM_31_62/assets/113016544/0501b457-731e-468b-aa27-2090d229e560


### Condition 3: Moving as a Rectangel 1 m^2 

Real robot

https://github.com/tanakon-apit/FRA532EXAM_31_62/assets/113016544/ec2ba63c-3cce-4e46-87ad-9b48824cea12

Rviz

https://github.com/tanakon-apit/FRA532EXAM_31_62/assets/113016544/2b03bb24-1181-4c25-8573-e12a26884475

Odom 

| x [actual] | y [actual] | x [estimated]| y_real [estimated]| x [error] | y [error] | x [square error] | y [square error]
| :---: | :---:| :---: | :---: | :---: | :---:| :---: | :---: |
| -0.054 | 0.032 | 0.063 | -0.086 | -0.117 | 0.118 | 0.013689 | 0.013924 |
| -0.152 | 0.206 | -0.008 | 0.032 | -0.144 | 0.174 | 0.020736 | 0.030276 |
| -0.106 | 0.211 | 0.123 | -0.137 | -0.229 | 0.348 | 0.052441 | 0.121104 |

| x [rmse] | y [rmse] |
| :---: | :---: |
| 0.170162667 | 0.234736732 |

### 5.3 EKF Covariance Adjustment of Wheel Odometry and IMU

### Moving as a Rectangel 1 m^2 

Mark that cov of IMU is at path: src/calibration_gen/config/sensor_calibration.yaml

Based on an error of 5.2, we hypothesize that it stemmed from a misalignment in the robot's orientation. Therefore, we conducted an experiment to adjust the covariance of odom yaw aiming to enhance accuracy.

Odom + Gyro 

cov: odom yaw [0.1]

| x [actual] | y [actual] | x [estimated]| y_real [estimated]| x [error] | y [error] | x [square error] | y [square error]
| :---: | :---:| :---: | :---: | :---: | :---:| :---: | :---: |
| -0.041 | -0.012 | 0.155 | -0.176 | -0.196 | 0.164 | 0.038416 | 0.026896 |
| -0.158 | 0.104 | -0.029 | -0.08 | -0.129 | 0.184 | 0.016641 | 0.033856 |
| -0.095 | 0.235 | 0.092 | 0.111 | -0.187 | 0.124 | 0.034969 | 0.015376 |

| x [rmse] | y [rmse] |
| :---: | :---: |
| 0.173230097 | 0.159298462 |

Odom + Gyro

cov: odom yaw [1.00E-6]

| x [actual] | y [actual] | x [estimated]| y_real [estimated]| x [error] | y [error] | x [square error] | y [square error]
| :---: | :---:| :---: | :---: | :---: | :---:| :---: | :---: |
| -0.16 | 0.05 | -0.038 | -0.125 | -0.122 | 0.175 | 0.014884 | 0.030625 |
| 0.795 | 0.317 | 0.876 | 0.572 | -0.081 | -0.255 | 0.006561 | 0.065025 |
| -0.135 | 0.084 | 6.00E-02 | -9.20E-02 | -0.195 | 0.176 | 0.038025 | 0.030976 |

| x [rmse] | y [rmse] |
| :---: | :---: |
| 0.14079536 | 0.14079536 |

Odom + Gyro

cov: odom yaw [1.00E-9]

| x [actual] | y [actual] | x [estimated]| y_real [estimated]| x [error] | y [error] | x [square error] | y [square error]
| :---: | :---:| :---: | :---: | :---: | :---:| :---: | :---: |
| -0.063 | 0.114 | 1.62E-01 | -7.60E-02 | -0.225 | 0.19 | 0.050625 | 0.0361 |
| -0.203 | 0.174 | -9.60E-02 | 4.30E-02 | -0.107 | 0.131 | 0.011449 | 0.017161 |
| -0.043 | 0.099 | 1.04E-01 | -4.00E-02 | -0.147 | 0.139 | 0.021609 | 0.019321 |

| x [rmse] | y [rmse] |
| :---: | :---: |
| 0.167015967 | 0.155544206 |

For the last part we add on acceleration to test whether it could enhance the performance of the x-axis.

Odom + Gyro + Accel

cov: odom x [1.00E-6] / odom yaw [0.1]

| x [actual] | y [actual] | x [estimated]| y_real [estimated]| x [error] | y [error] | x [square error] | y [square error]
| :---: | :---:| :---: | :---: | :---: | :---:| :---: | :---: |
| -0.11 | 0.066 | 0.0077 | -0.056 | -0.1177 | 0.122 | 0.01385329 | 0.014884 |
| -0.018 | -0.12 | 0.164 | -0.09 | -0.182 | -0.03 | 0.033124 | 0.0009 |
| -0.115 | 0.307 | -0.002 | 0.086 | -0.113 | 0.221 | 0.012769 | 0.048841 |

| x [rmse] | y [rmse] |
| :---: | :---: |
| 0.141122039 | 0.146770796 |

### 5.4 Motion Following at different scenario

1) Rectangle

https://github.com/tanakon-apit/FRA532EXAM_31_62/assets/113016544/5844b3e2-fbc3-4b32-ac53-257e1ba0e6fb

![alt text](image.png)

2) Circle

https://github.com/tanakon-apit/FRA532EXAM_31_62/assets/113016544/0770c518-3ad6-4356-a275-bf331a94af1a

![alt text](image-1.png)

3) Half-circle

https://github.com/tanakon-apit/FRA532EXAM_31_62/assets/113016544/0c7eb00d-0178-4921-8d56-f1940b813373

![alt text](image-2.png)



### Condition 1: Evaluation in Condition of No Additional Obstacles

1. Evaluating Robot Movement Narrow / Wide Doorway 

2. Evaluating Robot Movement Narrow / Wide Pathways 

3. Evaluating Robot Movement in Narrow Angles / Compact Spaces

### Video of Modify VFF Algorithm Testing

&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; [![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/JB25mcsy4QA/0.jpg)](https://www.youtube.com/watch?v=Tkn7DVA4PY4)

### Video of Modify VFF Algorithm Testing

&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; [![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/JB25mcsy4QA/0.jpg)](https://www.youtube.com/watch?v=JB25mcsy4QA)

### Condition 2: Evaluation in Condition of Additional Obstacles

1. Evaluating Robot Movement in the middle of Wide Pathways with (Cylindrical / Cube)

<img src="https://github.com/tuchapong1234/Lab1-Local-Planner/assets/113016544/8551e69c-0ab8-4a45-bd59-f6df07123bcd" width="500" height="500">

<img src="https://github.com/tuchapong1234/Lab1-Local-Planner/assets/113016544/6b02df88-5e93-4c46-aed4-4b73824ea775" width="500" height="500">

3. Evaluating Robot Movement offset from the middle of Wide Pathways with (Cylindrical / Cube)

<img src="https://github.com/tuchapong1234/Lab1-Local-Planner/assets/113016544/5da0cc1b-ab2a-45ce-be99-2833a34b9316" width="500" height="500">

<img src="https://github.com/tuchapong1234/Lab1-Local-Planner/assets/113016544/babb0aa4-4d38-4bb4-81de-93b5370934d2" width="500" height="500">


5. Evaluating Robot Movement at the corner with (Cylindrical / Cube)

<img src="https://github.com/tuchapong1234/Lab1-Local-Planner/assets/113016544/23c701c3-f607-4b4e-895a-0db099b17830" width="500" height="500">

<img src="https://github.com/tuchapong1234/Lab1-Local-Planner/assets/113016544/71d2d065-001b-4540-a91e-d4f151fb218a" width="500" height="500">

### 5.2 Comparing Result between Standard VFF Algorithm & Modify VFF Algorithm



### Conclusion

From experiments, it has been found that the estimated values from the Extended Kalman Filter (EKF) currently have a relatively high error due to inaccuracies in estimating the heading of the robot. This arises from rounding gyro values to address drift issues in estimation. However, this simultaneously results in the robot's estimated heading being lower than it should be.

A suggested approach to mitigate this issue is to employ a thresholding method, which can help alleviate the problem. Nonetheless, this would require adjusting the covariance values accordingly. Importantly, since most of the errors stem from the heading of the robot, using an IMU capable of estimating absolute heading can significantly improve the accuracy of the robot's estimation.






